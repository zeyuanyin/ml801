{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeyuanyin/ml801/blob/main/lab_2/lab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhoT7PfbBgKg"
      },
      "source": [
        "## Foundations and Advanced Topics in Machine Learning Lab ML801b -- Deep Learning (2)\n",
        "\n",
        "\n",
        "Lab Goal: Develop a compressed/efficient model with few numbers of parameters and FLOPs.\n",
        "\n",
        "- Pruning\n",
        "    - Fine-grained Pruning\n",
        "    - Channel-level Pruning\n",
        "\n",
        "\n",
        "<img src=\"./prune-1.png\" alt=\"Image\" style=\"width:50%;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCRlXB4bBgKi"
      },
      "source": [
        "### Part 1: Evaluate a pretrained neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EZ4rzUpdBgKi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load and normalize the CIFAR10 test dataset using torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfO7hGiyBgKk",
        "outputId": "f74bbb48-80c7-4400-ddc6-658494f44865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:16<00:00, 10311984.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "print(\"==> Preparing data..\")\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=transform_test\n",
        ")\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Building model..\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): Identity()\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(\"==> Building model..\")\n",
        "\n",
        "model = torchvision.models.get_model(\"resnet18\", num_classes=10).cuda()\n",
        "model.conv1 = nn.Conv2d(\n",
        "    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
        ")\n",
        "model.maxpool = nn.Identity()\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the pretrained weights into the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/zeyuanyin/ml801/releases/download/lab2/cifar10_resnet18_ckpt.pth\" to /home/zeyuan/.cache/torch/hub/checkpoints/cifar10_resnet18_ckpt.pth\n",
            "100%|██████████| 42.7M/42.7M [00:02<00:00, 20.2MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_weights_url = \"https://github.com/zeyuanyin/ml801/releases/download/lab2/cifar10_resnet18_ckpt.pth\"\n",
        "state_dict = torch.hub.load_state_dict_from_url(model_weights_url)['state_dict']\n",
        "state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()} # unwrap the module prefix (caused by DataParallel)\n",
        "\n",
        "model.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7DoXHyXjBgKk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 113.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 94.92%(9492/10000)\n",
            "==> Evaluate: non-pruned model's accuracy = 94.92%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model):\n",
        "    model.eval().cuda()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(testloader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print(\"Accuracy: {:.2f}%({}/{})\".format(100.0 * correct / total, correct, total))\n",
        "\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "acc = evaluate(model)\n",
        "\n",
        "print(\"==> Evaluate: non-pruned model's accuracy = {:.2f}%\".format(acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 2: Fine-grained Pruning\n",
        "\n",
        "<img src=\"./prune-2.png\" alt=\"Image\" style=\"width:50%;\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fine_grained_pruning(model, pruning_ratio):\n",
        "    # step 1: collect all the weights\n",
        "    weight_list = []\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            weight_list.append(module.weight.data.view(-1).abs().clone())\n",
        "\n",
        "\n",
        "    # step 2: get the threshold according to the global ranking\n",
        "    weight_concat = torch.cat(weight_list, dim=0)\n",
        "    sorted_weight, _ = torch.sort(weight_concat)\n",
        "    thre_index = int(len(sorted_weight) * pruning_ratio)\n",
        "    thre = sorted_weight[thre_index]\n",
        "\n",
        "    print(\"==> global threshold: {:.4f}\".format(thre))\n",
        "\n",
        "    # step 3: set the weight to zero according to the threshold\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            weight_copy = module.weight.data.abs().clone()\n",
        "            mask = (weight_copy > thre).float().cuda()\n",
        "            # if mask is one, then the corresponding weight will be retained\n",
        "            # if mask is zero, then the corresponding weight will be pruned\n",
        "            module.weight.data.mul_(mask)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> global threshold: 0.0108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 118.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 44.71%(4471/10000)\n",
            "==> Evaluate: 90.0% pruning model's accuracy = 44.71%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(state_dict)\n",
        "\n",
        "pruning_ratio = 0.9\n",
        "model = fine_grained_pruning(model, pruning_ratio)\n",
        "acc = evaluate(model)\n",
        "print(f\"==> Evaluate: {pruning_ratio*100}% pruning model's accuracy = {acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 3: Channel-level Pruning\n",
        "\n",
        "<img src=\"./prune-3.png\" alt=\"Image\" style=\"width:50%;\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fine_channel_level_pruning(model, pruning_ratio):\n",
        "    # step 1: batchnorm's gamma is the weights we want to prune\n",
        "    gamma_weight_list = []\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, nn.BatchNorm2d):\n",
        "            gamma_weight_list.append(module.weight.data.abs().clone().cuda())\n",
        "\n",
        "    # step 2: get the threshold according to the global ranking\n",
        "    gamma_weight_concat = torch.cat(gamma_weight_list, dim=0)\n",
        "    sorted_gamma_weight, _ = torch.sort(gamma_weight_concat)\n",
        "    thre_index = int(len(sorted_gamma_weight) * pruning_ratio)\n",
        "    thre = sorted_gamma_weight[thre_index]\n",
        "\n",
        "    print(\"==> global threshold: {:.4f}\".format(thre))\n",
        "\n",
        "    # step 3: set the weight to zero according to the threshold\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, nn.BatchNorm2d):\n",
        "            weight_copy = module.weight.data.abs().clone()\n",
        "            mask = (weight_copy > thre).float().cuda()\n",
        "            # if mask is one, then the corresponding weight will be retained\n",
        "            # if mask is zero, then the corresponding weight will be pruned\n",
        "            module.weight.data.mul_(mask)\n",
        "            module.bias.data.mul_(mask)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> global threshold: 0.0869\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 108.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 80.80%(8080/10000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(state_dict)\n",
        "pruning_ratio = 0.4\n",
        "model = fine_channel_level_pruning(model, pruning_ratio)\n",
        "acc = evaluate(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PthmMiiCBgKn"
      },
      "source": [
        "### Practice in Class:（not graded）\n",
        "\n",
        "Now it's your turn. \n",
        "\n",
        "- Try different pruning ratios and see how the evaluation accuracy changes, you can plot the **accuracy vs. pruning ratio curve**.\n",
        "- Try different models on different datasets, like CIFAR100. (Codebase is available at https://github.com/kuangliu/pytorch-cifar). Some other pretrained model are provided here\n",
        "    -  ResNet-50 on CIFAR-10: https://github.com/zeyuanyin/ml801/releases/download/lab2/cifar10_resnet50_ckpt.pth\n",
        "    -  ResNet-18 on CIFAR-100: https://github.com/zeyuanyin/ml801/releases/download/lab2/cifar100_resnet18_ckpt.pth\n",
        "    -  ResNet-50 on CIFAR-100: https://github.com/zeyuanyin/ml801/releases/download/lab2/cifar100_resnet50_ckpt.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoreGG9wBgKn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWOxgzz9BgKn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
